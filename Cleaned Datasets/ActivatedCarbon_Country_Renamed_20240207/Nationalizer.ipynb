{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countrynames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m countrynames\u001b[38;5;241m.\u001b[39mto_code(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countrynames' is not defined"
     ]
    }
   ],
   "source": [
    "from normality import normalize\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from countrynames import to_code\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ISOToEcoInventToolSub/Geographies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m             os\u001b[38;5;241m.\u001b[39mremove(file_path)\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m geo_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ISOToEcoInventToolSub/Geographies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_to_fix)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ISOToEcoInventToolSub/Geographies.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_to_fix = \"ActivatedCarbon_MVPVersion01_EF_20230621.csv\"\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "formatted_date = now.strftime(\"%Y%m%d\")\n",
    "folder_path = \"%s_Country_Renamed_%s\" %(csv_to_fix.split(\"_\")[0], formatted_date)\n",
    "os.makedirs(folder_path)\n",
    "\n",
    "files_to_keep = [csv_to_fix, 'ISOToEcoInventToolSub/Geographies.csv']\n",
    "def delete_csv_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv') and file not in files_to_keep:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "geo_df = pd.read_csv(\"./ISOToEcoInventToolSub/Geographies.csv\")\n",
    "df = pd.read_csv(csv_to_fix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country of Applicability'].unique()\n",
    "df['Country of Applicability'] = 'GLO'\n",
    "df.to_csv(\"./%s/%s.csv\"  %(folder_path, folder_path), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(country):\n",
    "    \"\"\"Clean up a country name before comparison.\"\"\"\n",
    "    return normalize(country, latinize=True)\n",
    "\n",
    "df_ambig = pd.DataFrame(columns=[\"Input string\", \"Mapped name\", \"Mapped code\", \"Quarantine?\"])\n",
    "\n",
    "def mapping(country:str)->str:\n",
    "    global df_ambig\n",
    "    if(result:=to_code(country)) is not None:\n",
    "        return result\n",
    "    matching_rows = df_ambig[df_ambig[\"Input string\"].str.contains(country, case=False, na=False)]\n",
    "    if not matching_rows.empty:\n",
    "        return country\n",
    "    else:\n",
    "        longname = process.extractOne(country, choices=geo_df['Name'], processor=(lambda x: str(x)), scorer=fuzz.token_set_ratio, score_cutoff=0)[0]\n",
    "        shortname = geo_df[geo_df['Name'] == longname]['Shortname'].iloc[0]\n",
    "        new_row = pd.DataFrame([{ \n",
    "            \"Input string\": country,\n",
    "            \"Mapped name\": longname,\n",
    "            \"Mapped code\": shortname}])\n",
    "        df_ambig = pd.concat([df_ambig, new_row], ignore_index=True)\n",
    "        return country\n",
    "    \n",
    "Region_column_name = 'Country of Applicability'\n",
    "df[Region_column_name] = df[Region_column_name].apply(normalize_name)\n",
    "df[Region_column_name] =df[Region_column_name].apply(lambda x: mapping(x))\n",
    "\n",
    "df_ambig.to_csv(\"ambig.csv\", index=False, sep='|')\n",
    "df_ambig.to_csv(\"./%s/AMBIG_%s.csv\" %(folder_path, folder_path), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"Go to ambig.csv and correct ambiguous inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Input string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input string'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merged_df, removed_rows_df\n\u001b[1;32m     25\u001b[0m corrected, further_quarantined \u001b[38;5;241m=\u001b[39m split_ambig()\n\u001b[0;32m---> 26\u001b[0m merged_df, removed_rows_df \u001b[38;5;241m=\u001b[39mremove_quarantined(df, further_quarantined, corrected)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mremove_quarantined\u001b[0;34m(df_first_clean, further_quarantined, corrected)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_quarantined\u001b[39m(df_first_clean, further_quarantined, corrected):\n\u001b[0;32m---> 10\u001b[0m     overlap_values \u001b[38;5;241m=\u001b[39m further_quarantined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput string\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     11\u001b[0m     removed_rows_df \u001b[38;5;241m=\u001b[39m df_first_clean[df_first_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry of Applicability\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(overlap_values)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     12\u001b[0m     df_second_clean \u001b[38;5;241m=\u001b[39m df_first_clean[\u001b[38;5;241m~\u001b[39mdf_first_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry of Applicability\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(overlap_values)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input string'"
     ]
    }
   ],
   "source": [
    "def split_ambig():\n",
    "    ambig = pd.read_csv('./ambig.csv')\n",
    "    if ambig.empty:\n",
    "        return ambig, ambig\n",
    "    corrected = ambig[ambig['Quarantine?'] != 'x']\n",
    "    further_quarantined = ambig[ambig['Quarantine?'] == 'x']\n",
    "    return corrected, further_quarantined\n",
    "\n",
    "def remove_quarantined(df_first_clean, further_quarantined, corrected):\n",
    "    overlap_values = further_quarantined['Input string'].unique()\n",
    "    removed_rows_df = df_first_clean[df_first_clean['Country of Applicability'].isin(overlap_values)].copy()\n",
    "    df_second_clean = df_first_clean[~df_first_clean['Country of Applicability'].isin(overlap_values)]\n",
    "    \n",
    "    merged_df = pd.merge(df_second_clean, corrected, left_on='Country of Applicability', right_on='Input string', how='left')\n",
    "    merged_df.loc[merged_df['Input string'].notna(), 'Country of Applicability'] = merged_df['Mapped code']\n",
    "    merged_df.drop(columns=['Mapped code', \"Input string\",\"Mapped name\",\"Quarantine?\"], inplace=True)\n",
    "    \n",
    "    file_path = \"./ambig.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        shutil.move(file_path, \"./%s/ambig_VERIFIED_%s.csv\" % (folder_path, folder_path))\n",
    "    return merged_df, removed_rows_df\n",
    "\n",
    "\n",
    "\n",
    "corrected, further_quarantined = split_ambig()\n",
    "merged_df, removed_rows_df =remove_quarantined(df, further_quarantined, corrected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CSHH', 'KG', 'EE', 'DJ', 'UN-SAFRICA', 'LS', 'KR', 'RER', 'NP',\n",
       "       'GR', 'RO', 'UN-SAMERICA', 'SZ', 'BZ', 'PE', 'BW', 'US', 'MW',\n",
       "       'TW', 'DM', 'IR', 'BO', 'ZW', 'AO', 'ET', 'LR', 'CO', 'ZM', 'AT',\n",
       "       'SD', 'TG', 'MA', 'VC', 'BF', 'SAS', 'GH', 'BE/LU', 'UN-EASIA',\n",
       "       'UN-SEUROPE', 'MS', 'UN-NAFRICA', 'RAS', 'WEU', 'IE', 'IQ', 'MX',\n",
       "       'FM', 'GW', 'AU', 'NO', 'UN-AUSTRALIANZ', 'EU', 'RNA',\n",
       "       'UN-AMERICAS', 'UN-MELANESIA', 'LY', 'ES', 'CN', 'PY', 'UN-WASIA',\n",
       "       'RU', 'DK', 'PH', 'BJ', 'LB', 'LT', 'IT', 'AR', 'PA', 'YE', 'KP',\n",
       "       'NZ', 'LK', 'BB', 'GU', 'ZA', 'MZ', 'HN', 'GB', 'FR', 'HU', 'DZ',\n",
       "       'UN-MAFRICA', 'KE', 'TD', 'MG', 'ML', 'GT', 'NE', 'GM', 'SK', 'CL',\n",
       "       'UN-EAFRICA', 'UZ', 'NG', 'UN-NEUROPE', 'LA', 'VE', 'UN-SEASIA',\n",
       "       'OM', 'IN', 'UY', 'MR', 'GY', 'AL', 'RS', 'PK', 'CSXX', 'CD', 'PS',\n",
       "       'MN', 'KZ', 'CV', 'JM', 'CY', 'VN', 'ST', 'BG', 'PL', 'HT', 'CF',\n",
       "       'GE', 'MD', 'IL', 'Central Asia', 'SB', 'UN-POLYNESIA', 'RW',\n",
       "       'OECD', 'NL', 'DO', 'SO', 'TR', 'UA', 'BM', 'UN-OCEANIA', 'TH',\n",
       "       'MY', 'AF', 'CH', 'CR', 'MM', 'RAF', 'AZ', 'TM', 'CU',\n",
       "       'UN-CAMERICA', 'KW', 'BN', 'BR', 'PT', 'CM', 'ME', 'SL', 'GN',\n",
       "       'GA', 'LU', 'GLO', 'BA', 'CA', 'AE', 'BI', 'JP', 'ID', 'KM', 'TN',\n",
       "       'GD', 'TL', 'MK', 'DE', 'MT', 'EG', 'MV', 'FJ', 'SI', 'UN-WAFRICA',\n",
       "       'KH', 'SY', 'UN-EEUROPE', 'NC', 'SR', 'CI', 'AM', 'SE', 'CG', 'PF',\n",
       "       'BT', 'TJ', 'FI', 'PG', 'HR', 'NI', 'SN', 'TT', 'UN-CARIBBEAN',\n",
       "       'PR', 'BE', 'SV', 'ER', 'YUG', 'QA', 'NA', 'CZ', 'SA', 'UG', 'TZ',\n",
       "       'EC', 'BD', 'SS', 'JO', 'BS', 'BY', 'SUHH', 'MU', 'FO', 'GF', 'KN',\n",
       "       'AG', 'BH', 'LV', 'VU', 'GP', 'IS', 'EH', 'LC', 'RE'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this cell, please add any code you'd like to edit \n",
    "merged_df[\"Country of Applicability\"].unique()\n",
    "removed_rows_df.head(15)\n",
    "rows_to_move = merged_df[merged_df['Country of Applicability'] == 'annex i countries']\n",
    "removed_rows_df = pd.concat([removed_rows_df, rows_to_move], ignore_index=True)\n",
    "merged_df = merged_df[merged_df['Country of Applicability'] != 'annex i countries']\n",
    "merged_df.loc[merged_df['Country of Applicability'] == 'asia', 'Country of Applicability'] = 'RAS'\n",
    "merged_df.loc[merged_df['Country of Applicability'] == 'africa', 'Country of Applicability'] = 'RAF'\n",
    "merged_df['Country of Applicability'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CropResidueEmissions_Country_Renamed_20240207/CropResidueEmissions_MVPVersion01_EF_20230621.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"Look through each dataset and adjust any inconsistent values\")\n",
    "\n",
    "removed_rows_df.to_csv(\"./%s/%s_further_quarantined.csv\" %(folder_path, folder_path), index=False) \n",
    "merged_df.to_csv(\"./%s/%s.csv\"  %(folder_path, folder_path), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(\"./Nationalizer.ipynb\", \"%s\" % folder_path)\n",
    "shutil.move(csv_to_fix, \"%s\" % folder_path)\n",
    "shutil.make_archive(folder_path.split('.')[0], 'zip', folder_path)\n",
    "shutil.rmtree(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
